Atenção:
- Não edite este ficheiro em programas como Word e afins. Use exclusivamente um editor de texto simples. Em caso de dúvida, use o editor do Spyder.
- Não altere a estrutura deste ficheiro. Preencha as respostas apenas nos espaços respectivos (a seguir à tag R#:)
- Pode adicionar linhas no espaço para as respostas mas as respostas devem ser sucintas e directas.

QUESTÔES:

Q1: Considerando os dados fornecidos, explique a necessidade de standardizar os valores dos atributos.
R1: Os dados representados são continuos e estão escalados de forma diferente, enquanto x1 e x4 variam entre ~-1 e 2, os valores de x2 e x3 variam entre ~ 20 e 30. 
Esta diferença de escala tem impacto directo em alguns algoritmos utilizados na minimizaçao da função custo, pois diminui a eficiencia do mesmo. 
(ie. o algoritmo gradient descendent ou SVM que optimiza distancias são afectados, o primeiro porque algoritmo evolui para um mínimo de forma mais depressa nas variaveis de menor dimensao o que provoque um 'zigzag' no movimento para o minimo, e o svm porque como lida com a mximização de distâncias de margem pode ser muito influenciado por uma variavel que tenha valores demasiado grandes.
O Feature scalling resolve esse problema colcando os valores na mesma escala. Embora em algumas técnicas, como regressão através das equações normais e naive bayes, 
a normalização ou standartização não serem relevantes, a maioria dos algoritmos de machine learning são efectadas pela escala dos dados e portanto é comum ser feito 
o feature scalling. 
A variável Y (de resposta) não deve ser 'standartizada', pois é binária. 


Q2: Explique como calculou os parâmetros para standardização e como os usou no conjunto de teste.
R2: Os parametros foram calculandos através do somatório da diferença entre as variáveis (excepto variável resposta) e a sua média, dividindo esse valor pelo 
respectivo desvio padrão. | data[:,:-1]-np.mean(data[:,:-1]))/np.std(data[:,:-1])



Q3: Explique como calculou a probabilidade a priori de um exemplo pertencer a uma classe (a probabilidade antes de ter em conta os valores dos atributos do exemplo) na sua implementação do classificador Naïve Bayes. Pode incluir um trecho relevante do código se ajudar a explicar.
R3: A probabilidade à priori de um dado exemplo é calculada a partir do numero de exemplos de determinada classe, sobre o numero de exemplos totais.
ou seja, P(Y==0)=(np.shape(X_train[Y_train==0,:])[0])/np.shape(X_train)[0]
como apenas existem duas classes, P(Y==1)=1-P(Y==0) 


Q4: Explique como o seu classificador Naïve Bayes prevê a classe a que um exemplo de teste pertence. Pode incluir um trecho relevante do código se ajudar a explicar.
R4: O classificador NV KDE implementado neste projecto prevê a classe da seguinte forma: numa primeira fase através do Kernel Density Estimation são calculadas as densidades 
das diferentes variaveis dos diferentes gupos da variaveis resposta (class 1 e 0). Neste projecto a função activate_KDE recebe como input os dados de treino e retorna dois
dicionarios com 4 chaves (4 variaveis) cada um com os respectivos de valores de densidade. 
Com estes valores foi implementada a funçao de previsão, que recebe uma entrada a classificar, os 8 KDE calculados anteriormente e as probabilidades à priori das classes.
Com estes dados é calculada a densidade da entrada para cada variável, sendo somadas de seguida para ser possível calcular a que classe pertence, utilizando Naive Bayes.
A class é dada pelo argumento que maximiza a probabilidade P(x\Y) , ou seja é calculada a probabilidade de x para ambas a classes e verificado qual o valor mais alto.
Utilizando numpy subtraiu-se prob(x\y==0)-prob(x\y==1); Os indices >=0 foram classificados com class==0 e os restantes class==1.
calc_0 = soma_prob0+math.log(priori0) #probabilidade sendo class 0 
calc_1 = soma_prob1+math.log(priori1) #prob sendo class 1
previsao=calc_0-calc_1
previsao=np.where(previsao>=0,0,1)


Q5: Explique que efeito tem o parâmetro de bandwidth no seu classificador.
R5: O efeito de bandwidth tem efeito na descriminacao do classificador, pois o seu valor define o peso de proximidade, ou seja, valores mais altos de bandwidth farão 
com que o classificador  seja mais generalista e considere valores mais longe da posição avaliada (um valor muito alto pode causar underfiting) , enquanto que se for 
mais baixo considerá apenas os valores mais proximos da posição, o que fará com que estimativa de treino seja mais precisa mas pouco generalista, causando overfiting. 
Assim, é de todo conveniente que sejam aplicadas tecnicas como o cross validation afim de escolher o valor optimo.   

Q6: Explique que efeito tem o parâmetro gamma no classificador SVM.
R6: De forma genérica o parâmetro gamma define o quão próximo tem que estar um exemplo para ser considerado na definição da 'decision boundary', quando o gamma é baixo
significa que valores mais longe são considerados para definir a linha de decisão, quando o gamma tem um valor alto significa que apenas os valores mais proximos vão ser considerados. Em suma, um valor muito pequeno de gamma poderá causar underfiting  enquanto que um valor muito alto poderá causar overfiting.


Q7: Explique como determinou o melhor parâmetro de bandwidth e gamma para o seu classificador e o classificador SVM. Pode incluir um trecho relevante do código se ajudar a explicar.
R7: Através da técnica Stratified Cross Validation que faz a divisão de forma proporcional foram optimizados ambos os valores. De forma ciclica efectuou-se a cross validation
para os diferentes modelos e respectivos parâmetros (bandwidth(h) e gamma(g)), onde em cada iteração foram treinados os modelos com os respectivos valores (h e g) e retirado o erro de treino e error de validação. No final das iterações pelos valores possiveis de gamma e bandwith foi verificado o indíce do valor minimo do set_erros de validação, indice que corresponde ao valor óptimo dos diferentes parametros. (os dados para treino do modelo foram divididos em 5 fold)

Q8: Explique como obteve a melhor hipótese para cada um dos classificadores depois de optimizados os parâmetros.
R8: Depois de optimizados os parâmetros, os classificadores (com os parâmetros) foram treinados com os dados de treino e de seguida foi verificado o seu erro real recorrendo 
aos dados de teste.


Q9: Mostre os melhores valores dos parâmetros optimizados, a estimativa do erro verdadeiro de cada uma das hipóteses que obteve (o seu classificador e os dois fornecidos pela biblioteca), os intervalos do número esperado de erros dados pelo teste normal aproximado e os valores dos testes de McNemar e discuta o que pode concluir daí.
R9: NB KDE - (melhor valor bandwidth: 0.06, erro de validacao:  0.0634, erro verdadeiro: 0.0834)
    Gaussian NB - (Erro Verdadeiro: 0.0922)
    SVM - (melhor gamma: 0.44, erro validação 0.2568, erro verdadeiro: 0.0593)
    O teste de macnemar dá os seguintes valores - NB KDE vs GNB:(0.0, 1.0), NV KDE vs SVM:(23.29032258064516, 1.392991340387617e-06), GNB vs SVM: (26.74074074074074,     2.3266392079612785e-07), analisando os valores pode dizer-se que os classificadores NB KDE e GNB têm um comportamento semelhante na classificação, pois 
    p(x)= 1 > p(a)=0.65, já as restantes comparações são rejeitados, pois os seus p(x) são menores que p(a).

Q10: (Opcional) Mostre a estimativa do erro verdadeiro do classificador SVM optimizado (se fez a parte opcional do trabalho) e discuta se valeu a pena fazer essa optimização. Se não fez a parte opcional do trabalho deixe esta resposta em branco.
R10:
