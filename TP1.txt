Atenção:
- Não edite este ficheiro em programas como Word e afins. Use exclusivamente um editor de texto simples. Em caso de dúvida, use o editor do Spyder.
- Não altere a estrutura deste ficheiro. Preencha as respostas apenas nos espaços respectivos (a seguir à tag R#:)
- Pode adicionar linhas no espaço para as respostas mas as respostas devem ser sucintas e directas.

QUESTÔES:

Q1: Considerando os dados fornecidos, explique a necessidade de standardizar os valores dos atributos.
R1: Os dados representados são continuos e estão escalados de forma diferente, enquanto x1 e x4 variam entre ~-1 e 2, os valores de x2 e x3 variam entre ~ 20 e 30. 
Esta diferença de escala tem impacto directo em alguns algoritmos utilizados na minimizaçao da função custo, pois diminui a eficiencia do mesmo. 
(ie. o algoritmo gradient descendent, que acham o minimo da função custo através da derivacao parcial de um learning rate,ou SVM que optimiza distancias, são afectados,
o primeiro porque algoritmo evolui para um mínimo de forma mais depressa nas variaveis de menor dimensao o que provoque um 'zigzag' no movimento para o minimo, 
e o svm porque como lida com a mximização de distâncias de margem pode ser muito influenciado por uma variavel que tenha valores demasiado grandes.
O Feature scalling resolve esse problema colcando os valores na mesma escala. Embora em algumas técnicas, como regressão através das equações normais e naive bayes, 
a normalização ou standartização não serem relevante, a maioria dos algoritmos de machine learning são efectadas pela escala dos dados e portanto é comum ser feito 
sempre o feature scalling. 
A variável Y (de resposta) não deve ser 'standartizada', pois é binária. 


Q2: Explique como calculou os parâmetros para standardização e como os usou no conjunto de teste.
R2: Os parametros foram calculandos através do somatório da diferença entre as variáveis (escepcao variável resposta) e a sua média, dividindo esse valor pelo 
respectivo desvio padrão. | data[:,:-1]-np.mean(data[:,:-1]))/np.std(data[:,:-1])



Q3: Explique como calculou a probabilidade a priori de um exemplo pertencer a uma classe (a probabilidade antes de ter em conta os valores dos atributos do exemplo) na sua implementação do classificador Naïve Bayes. Pode incluir um trecho relevante do código se ajudar a explicar.
R3: A probabilidade à priori de um dado exemplo é calculada a partir do numero de exemplos de determinada classe, sobre o numero de exemplos totais.
ou seja,  numerador=[i for i in Y if ==1]; denominador=Y.shape[0]; p(Y==1)=len(numerador)/denominador
como apenas existem duas classes, P(Y==0)=1-P(Y==1) 


Q4: Explique como o seu classificador Naïve Bayes prevê a classe a que um exemplo de teste pertence. Pode incluir um trecho relevante do código se ajudar a explicar.
R4:


Q5: Explique que efeito tem o parâmetro de bandwidth no seu classificador.
R5: O efeito de bandwidth tem efeito na descriminacao do classificardor, pois o seu valor define o peso de proximidade, ou seja, valores mais altos de bandwidth farão 
com que o classificador  seja mais generalista e considere valores mais longe da media de treino (um valor muito alto pode causar underfiting) , enquanto que se for 
mais baixo considerá apenas os valores mais proximos da média, o que fará com que estimativa de treino seja mais precisa, mas pode causar overfiting. Assim é de todo
conveniente que sejam aplicadas tecnicas como o cross validation afim de escolher o valor optimo.   

Q6: Explique que efeito tem o parâmetro gamma no classificador SVM.
R6:


Q7: Explique como determinou o melhor parâmetro de bandwidth e gamma para o seu classificador e o classificador SVM. Pode incluir um trecho relevante do código se ajudar a explicar.
R7:

Q8: Explique como obteve a melhor hipótese para cada um dos classificadores depois de optimizados os parâmetros.
R8:


Q9: Mostre os melhores valores dos parâmetros optimizados, a estimativa do erro verdadeiro de cada uma das hipóteses que obteve (o seu classificador e os dois fornecidos pela biblioteca), os intervalos do número esperado de erros dados pelo teste normal aproximado e os valores dos testes de McNemar e discuta o que pode concluir daí.
R9:


Q10: (Opcional) Mostre a estimativa do erro verdadeiro do classificador SVM optimizado (se fez a parte opcional do trabalho) e discuta se valeu a pena fazer essa optimização. Se não fez a parte opcional do trabalho deixe esta resposta em branco.
R10:

